# -*- coding: utf-8 -*-
"""ass_sup.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/146JNPaSK3ydxBGmuVZ_i2ahCZuDjnY4e
"""

import numpy as np
import pandas as pd

import seaborn as sns
import matplotlib as mpl
import matplotlib.pyplot as plt

from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor

from sklearn.metrics import mean_squared_error, r2_score,root_mean_squared_error

from sklearn.model_selection import train_test_split, KFold, cross_val_score, LeaveOneOut

data=pd.read_excel("/content/Pharmaceutical Supply Chain Optimization.xlsx")
data.head()

data.shape

data.describe()

data.info()

data.columns

missing = data.isnull().sum().sort_values(ascending=False)
missing = missing[missing > 0]
print("\nColumns with missing values:\n", missing)

data.isnull().sum()

# Count plot for categorical column drug
top_drugs = data['Drug'].value_counts()
plt.figure(figsize=(12,5))
sns.barplot(x=top_drugs.index, y=top_drugs.values)
plt.title("Top 10 Drugs Frequency", fontsize=14)
plt.xticks(rotation=45)
plt.ylabel("Count")
plt.show()

#Count plot for Restocking Strategy
plt.figure(figsize=(8,5))
sns.countplot(data=data, x='Restocking_Strategy', palette="Set3")
plt.title("Restocking Strategy Count", fontsize=14)
plt.xlabel("Restocking Strategy")
plt.ylabel("Count")
plt.show()

# Correlation heatmap
plt.figure(figsize=(6,4))
sns.heatmap(data[['Demand_Forecast', 'Optimal_Stock_Level']].corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title(" Correlation Heatmap")
plt.show()

numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()

def cap_iqr(df_, cols):
    df = df_.copy()
    for col in cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR
        # Cap values
        df[col] = np.where(df[col] < lower, lower, df[col])
        df[col] = np.where(df[col] > upper, upper, df[col])
    return df

df_capped = cap_iqr(data, numeric_cols)

lcoder= LabelEncoder()
data['Drug_label'] = lcoder.fit_transform(data['Drug'])
data['Restocking_Strategy_label'] = lcoder.fit_transform(data['Restocking_Strategy'])

X = data.drop(['Drug','Restocking_Strategy','Demand_Forecast'],axis=1)
Y = data['Demand_Forecast']

scaler_s = StandardScaler()
X_scaled_s = scaler_s.fit_transform(X)

Xtrain, Xtest, Ytrain, Ytest = train_test_split(X,Y,random_state=42,test_size=0.80)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(Xtrain)
X_test_scaled = scaler.transform(Xtest)

from sklearn.decomposition import PCA

pca = PCA(n_components=3) #Or PCA(0.95)
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

print("PCA Explained Variance Ratio:", pca.explained_variance_ratio_)

liner = LinearRegression()
liner_model = liner.fit(Xtrain,Ytrain)

RandomForest = RandomForestRegressor()
RF_model = RandomForest.fit(Xtrain,Ytrain)

Gradient_Boosting =  GradientBoostingRegressor()
GB_model = Gradient_Boosting.fit(Xtrain,Ytrain)

from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import RandomizedSearchCV

RandomForest = RandomForestRegressor()
RF_model = RandomForest.fit(Xtrain,Ytrain)

params = {
    'bootstrap': [True],
    'max_depth': [80, 100],
    'min_samples_split': [8, 12],
    'n_estimators': [100, 300]
}

from sklearn.model_selection import StratifiedKFold

cv_object = StratifiedKFold(n_splits = 2)

grid_search = GridSearchCV(estimator = RF_model, param_grid = params, cv = cv_object, verbose = 0, return_train_score = True)
grid_search.fit(X_train_scaled, Ytrain.ravel())

def result(model):
  Y_pre = model.predict(Xtest)
  mse = mean_squared_error(Ytest,Y_pre)
  rmse = root_mean_squared_error(Ytest,Y_pre)
  r2 = r2_score(Ytest, Y_pre)
  return mse,rmse,r2

models = [liner_model, RF_model, GB_model]
for i in models:
  mse,rmse, r2 = result(i)
  print("\tmodel: ",i)
  print("MSE: ",mse)
  print("RMSE: ",rmse)
  print("R2: ",r2)

# Model for cross-validation
model = LinearRegression()

# K-Fold Cross-Validation
kf = KFold(n_splits=5, shuffle=True, random_state=42)
kf_scores = cross_val_score(model, X_train_scaled, Ytrain, cv=kf)

print("K-Fold CV Scores:", kf_scores)





